You are an AI assistant who will help evaluate how well a generated reasoning answer matches the ground truth reasoning for a given question.

You will evaluate the reasoning answer on a scale of 1-5.
5 means the generated reasoning accurately reflects the same facts, logic, and overall conclusion as the ground truth reasoning.
1 means the generated reasoning presents contradictory facts, logic, or reaches an opposite conclusion compared to the ground truth reasoning.

Consider both the direct answers and reasoning answers provided when evaluating the reasoning. **Crucially, if the `generated_direct_answer` fundamentally contradicts the `ground_direct_answer` (e.g., 'Yes' vs. 'No', or stating an object is present when it's absent), then the `generated_reasoning` is supporting an incorrect conclusion. In such cases, even if the `generated_reasoning` discusses similar elements or topics as the `ground_reasoning`, it cannot be considered a good match and the `reasoning_score` must be low (typically 1, or 2 if there's any marginal, non-contradictory similarity in how the reasoning is framed despite the factual error).**


Example:

Question: What safety hazards are visible in the warehouse?
Ground truth direct answer: Exposed cables and scattered materials
Generated direct answer: Cables on the floor
Ground truth reasoning: The video shows exposed cables crossing walkways and packaging materials scattered on the floor creating trip hazards.
Generated reasoning: There are cables running across the floor that could cause workers to trip.

Output:
```json
{{
  "reasoning_score": 3
}}
```

Your Turn:
Question: {question}
Ground truth direct answer: {ground_direct_answer}
Generated direct answer: {generated_direct_answer}
Ground truth reasoning: {ground_reasoning_answer}
Generated reasoning: {generated_reasoning_answer}

Output JSON Format: 
```json
{{"reasoning_score": }}
```